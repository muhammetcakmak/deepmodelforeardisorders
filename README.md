The GitHub repository at contains a series of Python scripts designed for the analysis of gray-level co-occurrence matrix (GLCM) features using various machine learning models. Each script follows a structured approach:â€‹

ğŸ“Œ Overview
Middle ear diseases, if not diagnosed earlyâ€”especially in childrenâ€”can cause serious health issues. Current diagnostic methods are costly and prone to subjectivity. This project proposes a hybrid computer-aided diagnosis system to accurately classify four categories of ear conditions using a combination of textural and deep features.

ğŸ¦» Targeted Classes
Chronic Otitis Media

Earwax Plug (Cerumen Impaction)

Myringosclerosis

Normal (Healthy)

ğŸ“Š Dataset
Total Samples: 880 ear images

Classes: 4 (220 images per class)

Data Augmentation: Applied for balanced training

ğŸ§  Feature Extraction
ğŸ”¹ Textural Features
Gray-Level Co-occurrence Matrix (GLCM)

Local Binary Patterns (LBP)

Color Space transformations (HSV, YCbCr)

ğŸ”¹ Deep Features
EfficientNetV2 B0

Inception V3

ConvNeXtBase

ğŸ§ª Feature Selection Techniques
PCA (Principal Component Analysis)

ICA (Independent Component Analysis)

ReliefF

ğŸ” Classifiers Used
Support Vector Machine (SVM)

LightGBM

k-Nearest Neighbors (kNN)

Decision Tree (DT)

ğŸ† Best Performing Combinations
ConvNetBase + GLCM + ICA + SVM â†’ 99.58% Accuracy

EfficientNetV2B0 + Color-Space + ICA + SVM â†’ 99.58% Accuracy

These results indicate that the proposed hybrid model can serve as a reliable clinical decision support system in the diagnosis of ear diseases.

ğŸš€ How to Run
Clone the repository

Install requirements from requirements.txt

Organize the dataset structure as described in /data

Run main.py to train and evaluate models

Optional: Use visualize.py for Grad-CAM and feature maps

ğŸ“ Directory Structure

â”œâ”€â”€ data/  
â”‚   â”œâ”€â”€ Chronic_Otitis_Media/  
â”‚   â”œâ”€â”€ Earwax_Plug/  
â”‚   â”œâ”€â”€ Myringosclerosis/  
â”‚   â””â”€â”€ Normal/  
â”œâ”€â”€ features/  
â”œâ”€â”€ models/  
â”œâ”€â”€ utils/  
â”œâ”€â”€ main.py  
â”œâ”€â”€ README.md  
â””â”€â”€ requirements.txt  

We used:
  For textural feature extraction: LBP, Color-Space and GLCM models 
  For Deep Feature extraction, EfficieintNet, ConvNetBase and Inception V3 models 
  For feature selection, LDA and PCA 
  For classification, DT, SVM and LightGBM machine learning models 

1ï¸âƒ£ Extraction of textural features from images (LBP, GLCM, Color-Space transformation)
2ï¸âƒ£ Automatic feature extraction with deep learning models (EfficientNet, ConvNetBase, InceptionV3)
3ï¸âƒ£ Elimination of unnecessary features and reduction of data size with LDA and PCA
4ï¸âƒ£ Classification process with DT, SVM and LightGBM

ğŸ” Overview
The code implements a hybrid feature-based image classification pipeline that combines deep features extracted from a pre-trained InceptionV3 model and statistical color space features (RGB, HSV, LAB). These combined features are then reduced using Principal Component Analysis (PCA) and classified using a LightGBM classifier with 5-fold Stratified Cross-Validation. The final model is evaluated using metrics like Accuracy, Confusion Matrix, Classification Report, Mean Absolute Error (MAE), Cohenâ€™s Kappa Score, and Precision-Recall AUC.

ğŸ§  Feature Extraction: Deep + Color Features
A pretrained InceptionV3 model (include_top=False, pooling='avg') is used to extract 2048-dimensional deep features from images.

Alongside this, color-based features are computed:

RGB: Mean and standard deviation (3 + 3 = 6)

HSV: Mean and standard deviation (3 + 3 = 6)

LAB: Mean and standard deviation (3 + 3 = 6)

In total, 2048 + 18 = 2066-dimensional feature vectors are generated per image.

These features are concatenated into a single vector for each image.

ğŸ“ Data Loading and Preprocessing
The training and test datasets are stored in hierarchical folders.

Images are read using OpenCV (cv2.imread) and converted to RGB.

Each image is resized to 299Ã—299, normalized, and passed through the feature extractor.

The result is a feature matrix and corresponding label array.

ğŸ“‰ Dimensionality Reduction with PCA
Due to high feature dimensionality (2066), PCA is applied to reduce it to 100 components, preserving significant variance while improving efficiency and generalization.

ğŸ·ï¸ Label Encoding
The image labels (folder names) are encoded into integer values using LabelEncoder.

ğŸ§ª 5-Fold Stratified Cross-Validation with LightGBM
To ensure robustness and avoid overfitting, a StratifiedKFold is used.

For each fold:

A LightGBM classifier is trained using the training split.

Predictions and probabilities are generated for the validation split.

Evaluation metrics are computed for each fold:

Accuracy

Classification Report

Mean Absolute Error

Precision-Recall AUC

ğŸ“Š Evaluation Metrics and Visualization
After cross-validation, the following metrics are aggregated and reported:

âœ… Classification Report
Displays precision, recall, F1-score, and support for each class.

âœ… Confusion Matrix
A heatmap shows true vs. predicted labels.

âœ… Cohenâ€™s Kappa Score
Measures the agreement between predicted and actual labels beyond chance.

âœ… Precision-Recall Curve
Visualized for each fold, including the AUC score
+------------------+
|    Raw Images    |
+------------------+
         |
         v
+-------------------------------+
|     Feature Extraction        |
| - InceptionV3 (Deep features) |
| - RGB / HSV / LAB Stats       |
+-------------------------------+
         |
         v
+-------------------------------+
|    Feature Concatenation      |
+-------------------------------+
         |
         v
+-------------------------------+
|    PCA (Dim. Reduction)       |
+-------------------------------+
         |
         v
+-------------------------------+
|     LightGBM Classifier       |
|   (5-Fold Stratified CV)      |
+-------------------------------+
         |
         v
+-------------------------------+
|      Evaluation Metrics       |
| - Accuracy                    |
| - MAE, Kappa                  |
| - Confusion Matrix            |
| - PR Curve                    |
+-------------------------------+



ğŸ“Œ As a result:

Textural features enabled the model to perform more detailed analysis.
Deep learning models created strong representative features.
Data was optimized with feature selection and the success of machine learning models was increased.
Models such as LightGBM and SVM were used to achieve the highest classification accuracy.

ğŸš€ This study combined both traditional textural analysis and deep learning-based feature extraction to create a powerful classification model.
 Techniques such as Linear Discriminant Analysis (LDA), Principal Component Analysis (PCA), or ReliefF are applied to select or reduce features.â€‹ 
